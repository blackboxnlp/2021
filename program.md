
[Main page](index.md)

This year's BlackboxNLP workshop will have a hybrid programme. The first half of the program is entirely virtual, 
the second half is hosted both on-site and online. All plenary sessions will be held (either livestreamed or broadcasted) in Zoom
and followed by a live Q&A (unless the schedule indicates otherwise). Questions can be asked in the Zoom chat during the presentations. 
Poster sessions will be held on Gather.town. 
**The links to the zoom session and Gather.town space can be found on the Underline page of the workshop** (only accessible with conference registration).

<!-- You can find the programme [here](https://docs.google.com/spreadsheets/d/1SLJ07nMi6VoVOg5iEPSOv5v4cq_WopD8T0FJlr7X_wU/edit?usp=sharing). -->

Summary of the programme
---------------------------
**San Francisco (UTC-8) | Punta Cana (UTC-4) | London (UTC) | Beijing (UTC+8)**  
  
**22:00 - 22:15 | 02:00 - 02:15 | 06:00 - 06:15 | 14:00 - 14:15** Opening remarks. Zoom.  
**22:15 - 23:00 | 02:15 - 03:00 | 06:15 - 07:00 | 14:15 - 15:00** Keynote 1 (w/ Q&A): Willem Zuidema. Zoom.  
**23:00 - 23:15 | 03:00 - 03:15 | 07:00 - 07:15 | 15:00 - 15:15** Break.  
**23:15 - 00:00 | 03:15 - 04:00 | 07:15 - 08:00 | 15:15 - 16:00** Oral presentation session 1 (w/ Q&A). Zoom.  
**00:00 - 00:30 | 04:00 - 04:30 | 08:00 - 08:30 | 16:00 - 16:30** Break.  
**00:30 - 02:00 | 04:30 - 06:00 | 08:30 - 10:00 | 16:30 - 18:00** Poster session 1. Gather.town.  
**02:00 - 02:15 | 06:00 - 06:15 | 10:00 - 10:15 | 18:00 - 18:15** Break.  
**02:15 - 03:00 | 06:15 - 07:00 | 10:15 - 11:00 | 18:15 - 19:00** Oral presentation session 2 (w/ Q&A). Zoom.  
**03:00 - 03:30 | 07:00 - 07:30 | 11:00 - 11:30 | 19:00 - 19:30** Break.  
**03:30 - 04:00 | 07:30 - 08:00 | 11:30 - 12:00 | 19:30 - 20:00** Keynote 2 (w/o Q&A): Ana Marasović. Zoom.  
**04:00 - 04:30 | 08:00 - 08:30 | 12:00 - 12:30 | 20:00 - 20:30** Keynote 3 (w/o Q&A): Sara Hooker. Zoom.  
**04:30 - 04:45 | 08:30 - 08:45 | 12:30 - 12:45 | 20:30 - 20:45** Closing -- virtual program. Zoom.  
Break. Hybrid program starts.  
**05:00 - 05:15 | 09:00 - 09:15 | 13:00 - 13:15 | 21:00 - 21:15** Opening remarks and best paper award. On-site & Zoom.  
**05:15 - 06:00 | 09:15 - 10:00 | 13:15 - 14:00 | 21:15 - 22:00** Keynote 4 (w/ Q&A): Willem Zuidema. On-site & Zoom.  
**06:00 - 06:30 | 10:00 - 10:30 | 14:00 - 14:30 | 22:00 - 22:30** Oral presentation session 3 (w/ Q&A). On-site & Zoom.  
**06:30 - 07:00 | 10:30 - 11:00 | 14:30 - 15:00 | 22:30 - 23:00** Coffee break.  
**07:00 - 08:00 | 11:00 - 12:00 | 15:00 - 16:00 | 23:00 - 00:00** Poster session 2. Gather.town.  
**08:00 - 09:00 | 12:00 - 13:00 | 16:00 - 17:00 | 00:00 - 01:00** Lunch break.  
**09:00 - 09:45 | 13:00 - 13:45 | 17:00 - 17:45 | 01:00 - 01:45** Keynote 5 (w/ Q&A): Sara Hooker. On-site & Zoom.  
**09:45 - 10:15 | 13:45 - 14:15 | 17:45 - 18:15 | 01:45 - 02:15** Oral presentation session 4 (w/ Q&A). On-site & Zoom.  
**10:15 - 10:45 | 14:15 - 14:45 | 18:15 - 18:45 | 02:15 - 02:45** Coffee break.  
**10:45 - 12:15 | 14:45 - 16:15 | 18:45 - 20:15 | 02:45 - 04:15** Poster session 3. On-site & Gather.town.  
**12:15 - 10:45 | 16:15 - 14:45 | 20:15 - 18:45 | 04:15 - 02:45** Coffee break.  
**12:45 - 13:15 | 16:45 - 17:15 | 20:45 - 21:15 | 04:45 - 05:15** Oral presentation session 5 (w/ Q&A). On-site & Zoom.  
**13:15 - 14:00 | 17:15 - 18:00 | 21:15 - 22:00 | 05:15 - 06:00** Keynote 6 (w/ Q&A): Ana Marasović. On-site & Zoom.  
**14:00 - 14:15 | 18:00 - 18:15 | 22:00 - 22:15 | 06:00 - 06:15** Closing remarks. On-site & Zoom. 

<!-- | Session                               | Time          | Location              |
|:--------------------------------------|:--------------|:----------------------|
| Opening remarks                       |  2:00 - 2:15  | Zoom                  |
| Keynote 1 (w/ Q&A) -- Willem Zuidema  |  2:15 - 3:00  | Zoom                  |
| Break                                                 |                       |
| Oral presentation session 1           |  3:15 - 4:00  | Zoom                  |
| Break                                                 |                       |
| Poster session 1                      |  6:30 - 8:00  | gather.town           |
| Break                                                 |                       |
| Oral presentation session 2           |  6:15 - 7:00  | Zoom                  |
| Break                                                 |                       |
| Keynote 2 (w/o Q&A) -- Ana Marasović  |  7:30 - 8:00  | Zoom                  |
| Keynote 3 (w/o Q&A) -- Sara Hooker    |  8:00 - 8:30  | Zoom                  |
| Closing -- virtual program            |  8:30 - 8:45  | Zoom                  |
|-------------------------------------------------------|                       |
| Break. Hybrid program starts.                         |                       |
|-------------------------------------------------------|                       |
| Opening remarks and best paper award  |  9:00 - 9:15  | On-site & Zoom        |
| Keynote 4 (w/ Q&A) -- Willem Zuidema  |  9:15 - 10:00 | On-site & Zoom        |
| Oral presentation session 3           | 10:00 - 10:30 | On-site & Zoom        |
| Coffee break                                          |                       |
| Poster session 2                      | 11:00 - 12:00 | gather.town           |
| Lunch break                                           |                       |
| Keynote 5 (w/ Q&A) -- Sara Hooker     | 13:00 - 13:45 | On-site & Zoom        |
| Oral presentation session 4           | 13:45 - 14:15 | On-site & Zoom        |
| Coffee break                                          |                       |
| Poster session 3                      | 14:45 - 16:15 | On-site & gather.town |
| Coffee break                                          |                       |
| Oral presentation session 5           | 16:45 - 17:15 | On-site & Zoom        |
| Keynote 6 (w/ Q&A) -- Ana Marasović   | 17:15 - 18:00 | On-site & Zoom        |
| Closing remarks                       | 18:00 - 18:15 | On-site & Zoom        | -->



Oral presentation session 1 (Time indications: Punta Cana)
---------------------------
- **3:15 - 3:30**  _To what extent do human explanations of model behavior align with actual model behavior?_ Grusha Prasad, Yixin Nie, Mohit Bansal, Robin Jia, Douwe Kiela and Adina Williams.
- **3:30 - 3:45 (Live, w/ Q&A)** _Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings_. Laura Aina and Tal Linzen.
- **3:45 - 4:00 (Live, w/ Q&A)** _The Language Model Understood the Prompt was Ambiguous: Probing Syntactic Uncertainty Through Generation_. Hendrik Schuff, Hsiu-Yu Yang, Heike Adel and Ngoc Thang Vu.

Oral presentation session 2 (Time indications: Punta Cana)
---------------------------
- **6:15 - 6:30 (w/ Q&A)** _On the Limits of Minimal Pairs in Contrastive Evaluation_. Jannis Vamvas and Rico Sennrich.
- **6:30 - 6:45 (Live, w/ Q&A)** _Test Harder than You Train: Probing with Extrapolation Splits_. Jenny Kunz and Marco Kuhlmann.
- **6:45 - 7:00** _What Models Know About Their Attackers: Deriving Attacker Information From Latent Representations_. Zhouhang Xie, Jonathan Brophy, Adam Noack, Wencong You, Kalyani Asthana, Carter Perkins, Sabrina Reis, Zayd Hammoudeh, Daniel Lowd and Sameer Singh.

Oral presentation session 3 (Time indications: Punta Cana)
---------------------------
- **10:00 - 10:15 (w/ Q&A)** _On the Limits of Minimal Pairs in Contrastive Evaluation_. Jannis Vamvas and Rico Sennrich.
- **10:15 - 10:30 (Live, w/ Q&A)** _Test Harder than You Train: Probing with Extrapolation Splits_. Jenny Kunz and Marco Kuhlmann.

Oral presentation session 4 (Time indications: Punta Cana)
---------------------------
- **13:45 - 14:00** _What Models Know About Their Attackers: Deriving Attacker Information From Latent Representations_. Zhouhang Xie, Jonathan Brophy, Adam Noack, Wencong You, Kalyani Asthana, Carter Perkins, Sabrina Reis, Zayd Hammoudeh, Daniel Lowd and Sameer Singh.
- **14:00 - 14:15 (Live, w/ Q&A)** _To what extent do human explanations of model behavior align with actual model behavior?_ Grusha Prasad, Yixin Nie, Mohit Bansal, Robin Jia, Douwe Kiela and Adina Williams.

Oral presentation session 5 (Time indications: Punta Cana)
---------------------------
- **16:45 - 17:00 (Live, w/ Q&A)** _Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings_. Laura Aina and Tal Linzen.
- **17:00 - 17:15 (Live, w/ Q&A)** _The Language Model Understood the Prompt was Ambiguous: Probing Syntactic Uncertainty Through Generation_. Hendrik Schuff, Hsiu-Yu Yang, Heike Adel and Ngoc Thang Vu.

Poster session 1 (gather.town)
----------------
**Archival papers**
- _Can Transformers Jump Around Right in Natural Language? Assessing Performance Transfer from SCAN_. Rahma Chaabouni, Roberto Dessì and Eugene Kharitonov.
- _A howling success or a working sea? Testing what BERT knows about metaphors_. Paolo Pedinotti, Eliana Di Palma, Ludovica Cerini and Alessandro Lenci.
- _Variation and generality in encoding of syntactic anomaly information in sentence embeddings_. Qinxuan Wu and Allyson Ettinger.
- _Screening Gender Transfer in Neural Machine Translation_. Guillaume Wisniewski, Lichao Zhu, Nicolas Bailler and François Yvon.
- _What BERT Based Language Model Learns in Spoken Transcripts: An Empirical Study_. Ayush Kumar, Mukuntha Narayanan Sundararaman and Jithendra Vepa.
- _Assessing the Generalization Capacity of Pre-trained Language Models through Japanese Adversarial Natural Language Inference_. Hitomi Yanaka and Koji Mineshima.
- _Investigating Negation in Pre-trained Vision-and-language Models_. Radina Dobreva and Frank Keller.
- _How Familiar Does That Sound? Cross-Lingual Representational Similarity Analysis of Acoustic Word Embeddings_. Badr M. Abdullah, Iuliia Zaitova, Tania Avgustinova, Bernd Möbius and Dietrich Klakow.
- _Exploratory Model Analysis Using Data-Driven Neuron Representations_. Daisuke Oba, Naoki Yoshinaga and Masashi Toyoda.
- _ALL Dolphins Are Intelligent and SOME Are Friendly: Probing BERT for Nouns’ Semantic Properties and their Prototypicality_. Marianna Apidianaki and Aina Garí Soler.
- _Discrete representations in neural models of spoken language_. Bertrand Higy, Lieke Gelderloos, Afra Alishahi and Grzegorz Chrupała.
- _Multi-Layer Random Perturbation Training for improving Model Generalization Efficiently_. Lis Kanashiro Pereira, Yuki Taya and Ichiro Kobayashi.
- _On the Language-specificity of Multilingual BERT and the Impact of Fine-tuning_. Marc Tanti, Lonneke van der Plas, Claudia Borg and Albert Gatt.
- _Language Models Use Monotonicity to Assess NPI Licensing_. Jaap Jumelet, Milica Denic, Jakub Szymanik, Dieuwke Hupkes and Shane Steinert-Threlkeld.
- _Testing the linguistics of transformer generalizations_. Saliha Muradoglu and Mans Hulden.

**Extended abstracts**
- _BPE affects Training Data Memorization by Transformer Language Models_. Eugene Kharitonov, Marco Baroni and Dieuwke Hupkes.
- _Transformers Scan both Left and Right -- When they Have a Cue_. Jan H. Athmer and Denis Paperno.
- _Probing structures in the visual region embeddings from multimodal BERT_. Victor Milewski, Miryam de Lhoneux and Marie-Francine Moens.
- _Explaining Classes through Word Attributions_. Samuel Rönnqvist, Amanda Myntti, Aki-Juhani Kyröläinen, Sampo Pyysalo, Veronika Laippala and Filip Ginter.

**Findings papers**
- _Distilling Word Meaning in Context from Pre-trained Language Models_. Yuki Arase and Tomoyuki Kajiwara.
- _Probing Pre-trained Language Models for Semantic Attributes and their Values_. Meriem Beloucif.


Poster session 2 (gather.town)
----------------
**Archival papers**
- _ProSPer: Probing Human and Neural Network Language Model Understanding of Spatial Perspective_. Tessa Masis and Carolyn Anderson.
- _Can Transformers Jump Around Right in Natural Language? Assessing Performance Transfer from SCAN_. Rahma Chaabouni, Roberto Dessì and Eugene Kharitonov.
- _A howling success or a working sea? Testing what BERT knows about metaphors_. Paolo Pedinotti, Eliana Di Palma, Ludovica Cerini and Alessandro Lenci.
- _Efficient Explanations from Empirical Explainers_. Robert Schwarzenberg, Nils Feldhus and Sebastian Möller.
- _Variation and generality in encoding of syntactic anomaly information in sentence embeddings_. Qinxuan Wu and Allyson Ettinger.
- _Screening Gender Transfer in Neural Machine Translation_. Guillaume Wisniewski, Lichao Zhu, Nicolas Bailler and François Yvon.
- _Not all parameters are born equal: Attention is mostly what you need_. Nikolay Bogoychev.
- _An Investigation of Language Model Interpretability via Sentence Editing_. Samuel Stevens and Yu Su.
- _Relating Neural Text Degeneration to Exposure Bias_. Ting-Rui Chiang and Yun-Nung Chen.
- _What BERT Based Language Model Learns in Spoken Transcripts: An Empirical Study_. Ayush Kumar, Mukuntha Narayanan Sundararaman and Jithendra Vepa.
- _Assessing the Generalization Capacity of Pre-trained Language Models through Japanese Adversarial Natural Language Inference_. Hitomi Yanaka and Koji Mineshima.
- _How Familiar Does That Sound? Cross-Lingual Representational Similarity Analysis of Acoustic Word Embeddings_. Badr M. Abdullah, Iuliia Zaitova, Tania Avgustinova, Bernd Möbius and Dietrich Klakow.
- _The Acceptability Delta Criterion: Testing Knowledge of Language using the Gradience of Sentence Acceptability_. Héctor Vázquez Martínez.
- _Analyzing BERT's Knowledge of Hypernymy via Prompting_. Michael Hanna and David Mareček.
- _ALL Dolphins Are Intelligent and SOME Are Friendly: Probing BERT for Nouns’ Semantic Properties and their Prototypicality_. Marianna Apidianaki and Aina Garí Soler.
- _Discrete representations in neural models of spoken language_. Bertrand Higy, Lieke Gelderloos, Afra Alishahi and Grzegorz Chrupała.
- _Word Equations: Inherently Interpretable Sparse Word Embeddings through Sparse Coding_. Adly Templeton.
- _Learning Mathematical Properties of Integers_. Maria Ryskina and Kevin Knight.
- _Perturbing Inputs for Fragile Interpretations in Deep Natural Language Processing_. Sanchit Sinha, Hanjie Chen, Arshdeep Sekhon, Yangfeng Ji and Yanjun Qi. 
- _Interacting Knowledge Sources, Inspection and Analysis: Case-studies on Biomedical text processing_. Parsa Bagherzadeh and Sabine Bergler.
- _Attacks against Ranking Algorithms with Text Embeddings: {A} Case Study on Recruitment Algorithms_. Anahita Samadi, Debapriya Banerjee and Shirin Nilizadeh.
- _On the Language-specificity of Multilingual BERT and the Impact of Fine-tuning_. Marc Tanti, Lonneke van der Plas, Claudia Borg and Albert Gatt.
- _Training Dynamic based data filtering may not work for NLP datasets_. Arka Talukdar, Monika Dagar, Prachi Gupta and Varun Menon.
- _Controlled tasks for model analysis: Retrieving discrete information from sequences_. Ionut-Teodor Sorodoc, Gemma Boleda and Marco Baroni.
- _BERT Has Uncommon Sense: Similarity Ranking for Word Sense BERTology_. Luke Gessler and Nathan Schneider.
- _How Length Prediction Influence the Performance of Non-Autoregressive Translation?_ Minghan Wang, GUO Jiaxin, Yuxia Wang, Yimeng Chen, Su Chang, Hengchao Shang, Min Zhang, Shimin Tao and Hao Yang.
- _Language Models Use Monotonicity to Assess NPI Licensing_. Jaap Jumelet, Milica Denic, Jakub Szymanik, Dieuwke Hupkes and Shane Steinert-Threlkeld.
- _Do contextual language embeddings distinguish between intersective and strictly subsective adjectives?_ Michael Goodale and Salvador Mascarenhas.
- _Explaining NLP Models via Minimal Contrastive Editing (MiCE)_. Alexis Ross, Ana Marasović and Matthew Peters.
- _An in-depth look at Euclidean disk embeddings for structure preserving parsing_. Federico Fancellu, Lan Xiao, Allan Jepson and Afsaneh Fazly.

**Extended abstracts**
- _On Neurons Invariant to Sentence Structural Changes in Neural Machine Translation_. Gal Patel, Leshem Choshen and Omri Abend.
- _BPE affects Training Data Memorization by Transformer Language Models_. Eugene Kharitonov, Marco Baroni and Dieuwke Hupkes.
- _Transformers Scan both Left and Right -- When they Have a Cue_. Jan H. Athmer and Denis Paperno.
- _Probing structures in the visual region embeddings from multimodal BERT_. Victor Milewski, Miryam de Lhoneux and Marie-Francine Moens.
- _Putting Words in BERT's Mouth: Navigating Contextualized Vector Spaces with Pseudowords_. Taelin Karidi, Yichu Zhou, Nathan Schneider, Omri Abend and Vivek Srikumar.
- _Human Evaluation Study for Explaining Knowledge Graph Completion_. Timo Sztyler and Carolin Lawrence. 

**Findings papers**
- _Don't Discard All the Biased Instances: Investigating a Core Assumption in Dataset Bias Mitigation Techniques_.
- _Distilling Word Meaning in Context from Pre-trained Language Models_. Yuki Arase and Tomoyuki Kajiwara.
- _Probing Pre-trained Language Models for Semantic Attributes and their Values_. Meriem Beloucif.
- _Making Heads and Tails of Models with Marginal Calibration for Sparse Tagsets_. Michael Kranzlein, Nelson F. Liu and Nathan Schneider.


Poster session 3 (gather.town)
----------------
**Archival papers**
- _ProSPer: Probing Human and Neural Network Language Model Understanding of Spatial Perspective_. Tessa Masis and Carolyn Anderson.
- _Enhancing Interpretable Clauses Semantically using Pretrained Word Representation_. Rohan Kumar Yadav, Lei Jiao, Ole-Christoffer Granmo and Morten Goodwin.
- _Not all parameters are born equal: Attention is mostly what you need_. Nikolay Bogoychev.
- _Not All Models Localize Linguistic Knowledge in the Same Place: A Layer-wise Probing on BERToids’ Representations_. Mohsen Fayyaz, Ehsan Aghazadeh, Ali Modarressi, Hosein Mohebbi and Mohammad Taher Pilehvar.
- _Transferring Knowledge from Vision to Language: How to Achieve it and how to Measure it?_. Tobias Norlund, Lovisa Hagström and Richard Johansson.
- _Relating Neural Text Degeneration to Exposure Bias_. Ting-Rui Chiang and Yun-Nung Chen.
- _How Familiar Does That Sound? Cross-Lingual Representational Similarity Analysis of Acoustic Word Embeddings_. Badr M. Abdullah, Iuliia Zaitova, Tania Avgustinova, Bernd Möbius and Dietrich Klakow.
- _The Acceptability Delta Criterion: Testing Knowledge of Language using the Gradience of Sentence Acceptability_. Héctor Vázquez Martínez.
- _Exploratory Model Analysis Using Data-Driven Neuron Representations_. Daisuke Oba, Naoki Yoshinaga and Masashi Toyoda.
- _Learning Mathematical Properties of Integers_. Maria Ryskina and Kevin Knight.
- _Probing Language Models for Understanding of Temporal Expressions_. Shivin Thukral, Kunal Kukreja and Christian Kavouras.
- _Perturbing Inputs for Fragile Interpretations in Deep Natural Language Processing_. Sanchit Sinha, Hanjie Chen, Arshdeep Sekhon, Yangfeng Ji and Yanjun Qi. 
- _How Does BERT Rerank Passages? An Attribution Analysis with Information Bottlenecks_. Zhiying Jiang, Raphael Tang, Ji Xin and Jimmy Lin.
- _Training Dynamic based data filtering may not work for NLP datasets_. Arka Talukdar, Monika Dagar, Prachi Gupta and Varun Menon.
- _Controlled tasks for model analysis: Retrieving discrete information from sequences_. Ionut-Teodor Sorodoc, Gemma Boleda and Marco Baroni.
- _Fine-Tuned Transformers Show Clusters of Similar Representations Across Layers_. Jason Phang, Haokun Liu and Samuel R. Bowman.
- _An in-depth look at Euclidean disk embeddings for structure preserving parsing_. Federico Fancellu, Lan Xiao, Allan Jepson and Afsaneh Fazly.

**Extended abstracts**
- _Generalization in neural sequence models: a case study in symbolic mathematics_. Sean Welleck, Peter West, Jize Cao and Yejin Choi.

**Findings papers**
- _Influence Tuning: Demoting Spurious Correlations via Instance Attribution and Instance-Driven Updates_. Xiaochuang Han and Yulia Tsvetkov.
- _Probing Across Time: What Does RoBERTa Know and When?_ Leo Z. Liu, Yizhong Wang, Jungo Kasai, Hannaneh Hajishirzi and Noah A. Smith.
- _Generating Realistic Natural Language Counterfactuals_. Marcel Robeer.


Poster session 3 (On site)
----------------
**Archival papers**
- _Efficient Explanations from Empirical Explainers_. Robert Schwarzenberg, Nils Feldhus and Sebastian Möller.
- _Enhancing Interpretable Clauses Semantically using Pretrained Word Representation_. Rohan Kumar Yadav, Lei Jiao, Ole-Christoffer Granmo and Morten Goodwin.
- _Transferring Knowledge from Vision to Language: How to Achieve it and how to Measure it?_. Tobias Norlund, Lovisa Hagström and Richard Johansson.
- _Analyzing BERT's Knowledge of Hypernymy via Prompting_. Michael Hanna and David Mareček.
- _Explaining NLP Models via Minimal Contrastive Editing (MiCE)_. Alexis Ross, Ana Marasović and Matthew Peters.

**Extended abstracts**
- _On Neurons Invariant to Sentence Structural Changes in Neural Machine Translation_. Gal Patel, Leshem Choshen and Omri Abend.

**Findings papers**
- _Generating Realistic Natural Language Counterfactuals_. Marcel Robeer.
