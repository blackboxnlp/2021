
[Main page](index.md)

This year's BlackboxNLP workshop will have a hybrid programme. The first half of the program is entirely virtual, 
the second half is hosted both on-site and online. All plenary sessions will be held (either livestreamed or broadcasted) in Zoom
and followed by a live Q&A (unless the schedule indicates otherwise). Questions can be asked in the Zoom chat during the presentations. 
Poster sessions will be held on Gather.town. 
**The links to the zoom session and Gather.town space can be found on the Underline page of the workshop** (only accessible with conference registration).

You can find the programme [here](https://docs.google.com/spreadsheets/d/1SLJ07nMi6VoVOg5iEPSOv5v4cq_WopD8T0FJlr7X_wU/edit?usp=sharing).

Summary of the programme (Time indications: Punta Cana)
---------------------------
| Session                               | Time          | Location              |
|:--------------------------------------|:--------------|:----------------------|
| Opening remarks                       |  2:00 - 2:15  | Zoom                  |
| Keynote 1 (w/ Q&A) -- Willem Zuidema  |  2:15 - 3:00  | Zoom                  |
| Break                                                 |                       |
| Oral presentation session 1           |  3:15 - 4:00  | Zoom                  |
| Break                                                 |                       |
| Poster session 1                      |  6:30 - 8:00  | gather.town           |
| Break                                                 |                       |
| Oral presentation session 2           |  6:15 - 7:00  | Zoom                  |
| Break                                                 |                       |
| Keynote 2 (w/o Q&A) -- Ana Marasović  |  7:30 - 8:00  | Zoom                  |
| Keynote 3 (w/o Q&A) -- Sara Hooker    |  8:00 - 8:30  | Zoom                  |
| Closing -- virtual program            |  8:30 - 8:45  | Zoom                  |
|-------------------------------------------------------|                       |
| Break. Hybrid program starts.                         |                       |
|-------------------------------------------------------|                       |
| Opening remarks and best paper award  |  9:00 - 9:15  | On-site & Zoom        |
| Keynote 4 (w/ Q&A) -- Willem Zuidema  |  9:15 - 10:00 | On-site & Zoom        |
| Oral presentation session 3           | 10:00 - 10:30 | On-site & Zoom        |
| Coffee break                                          |                       |
| Poster session 2                      | 11:00 - 12:00 | gather.town           |
| Lunch break                                           |                       |
| Keynote 5 (w/ Q&A) -- Sara Hooker     | 13:00 - 13:45 | On-site & Zoom        |
| Oral presentation session 4           | 13:45 - 14:15 | On-site & Zoom        |
| Coffee break                                          |                       |
| Poster session 3                      | 14:45 - 16:15 | On-site & gather.town |
| Coffee break                                          |                       |
| Oral presentation session 5           | 16:45 - 17:15 | On-site & Zoom        |
| Keynote 6 (w/o Q&A) -- Ana Marasović  | 17:15 - 18:00 | On-site & Zoom        |
| Closing remarks                       | 18:00 - 18:15 | On-site & Zoom        |



Oral presentation session 1 (Time indications: Punta Cana)
---------------------------
- **3:15 - 3:30** _To what extent do human explanations of model behavior align with actual model behavior?_ Grusha Prasad, Yixin Nie, Mohit Bansal, Robin Jia, Douwe Kiela and Adina Williams.
- **3:30 - 3:45** _Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings_. Laura Aina and Tal Linzen.
- **3:45 - 4:00** _The Language Model Understood the Prompt was Ambiguous: Probing Syntactic Uncertainty Through Generation_. Hendrik Schuff, Hsiu-Yu Yang, Heike Adel and Ngoc Thang Vu.

Oral presentation session 2 (Time indications: Punta Cana)
---------------------------
- **6:15 - 6:30** _On the Limits of Minimal Pairs in Contrastive Evaluation_. Jannis Vamvas and Rico Sennrich.
- **6:30 - 6:45** _Test Harder than You Train: Probing with Extrapolation Splits_. Jenny Kunz and Marco Kuhlmann.
- **6:45 - 7:00** _What Models Know About Their Attackers: Deriving Attacker Information From Latent Representations_. Zhouhang Xie, Jonathan Brophy, Adam Noack, Wencong You, Kalyani Asthana, Carter Perkins, Sabrina Reis, Zayd Hammoudeh, Daniel Lowd and Sameer Singh.

Oral presentation session 3 (Time indications: Punta Cana)
---------------------------
- **10:00 - 10:15** _On the Limits of Minimal Pairs in Contrastive Evaluation_. Jannis Vamvas and Rico Sennrich.
- **10:15 - 10:30** _Test Harder than You Train: Probing with Extrapolation Splits_. Jenny Kunz and Marco Kuhlmann.

Oral presentation session 4 (Time indications: Punta Cana)
---------------------------
- **13:45 - 14:00** _What Models Know About Their Attackers: Deriving Attacker Information From Latent Representations_. Zhouhang Xie, Jonathan Brophy, Adam Noack, Wencong You, Kalyani Asthana, Carter Perkins, Sabrina Reis, Zayd Hammoudeh, Daniel Lowd and Sameer Singh.
- **14:00 - 14:15** _To what extent do human explanations of model behavior align with actual model behavior?_ Grusha Prasad, Yixin Nie, Mohit Bansal, Robin Jia, Douwe Kiela and Adina Williams.

Oral presentation session 5 (Time indications: Punta Cana)
---------------------------
- **16:45 - 17:00** _Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings_. Laura Aina and Tal Linzen.
- **17:00 - 17:15** _The Language Model Understood the Prompt was Ambiguous: Probing Syntactic Uncertainty Through Generation_. Hendrik Schuff, Hsiu-Yu Yang, Heike Adel and Ngoc Thang Vu.

Poster session 1 (gather.town)
----------------
**Archival papers**
- _Do Language Models Know the Way to Rome?_ Bastien Liétard, Mostafa Abdou and Anders Søgaard.
- _BERT Has Uncommon Sense: Similarity Ranking for Word Sense BERTology_. Luke Gessler and Nathan Schneider.
- _How Length Prediction Influence the Performance of Non-Autoregressive Translation?_ Minghan Wang, GUO Jiaxin, Yuxia Wang, Yimeng Chen, Su Chang, Hengchao Shang, Min Zhang, Shimin Tao and Hao Yang.
- _Language Models Use Monotonicity to Assess NPI Licensing_. Jaap Jumelet, Milica Denic, Jakub Szymanik, Dieuwke Hupkes and Shane Steinert-Threlkeld.
- _Do contextual language embeddings distinguish between intersective and strictly subsective adjectives?_ Michael Goodale and Salvador Mascarenhas.
- _Explaining NLP Models via Minimal Contrastive Editing (MiCE)_. Alexis Ross, Ana Marasović and Matthew Peters.
- _Testing the linguistics of transformer generalizations_. Saliha Muradoglu and Mans Hulden.
- _Fine-Tuned Transformers Show Clusters of Similar Representations Across Layers_. Jason Phang, Haokun Liu and Samuel R. Bowman.

**Extended abstracts**
- _BPE affects Training Data Memorization by Transformer Language Models_. Eugene Kharitonov, Marco Baroni and Dieuwke Hupkes.
- _Generalization in neural sequence models: a case study in symbolic mathematics_. Sean Welleck, Peter West, Jize Cao and Yejin Choi.
- _Human Evaluation Study for Explaining Knowledge Graph Completion_. Timo Sztyler and Carolin Lawrence.
- _Transformers Scan both Left and Right -- When they Have a Cue_. Jan H. Athmer and Denis Paperno.
- _Probing structures in the visual region embeddings from multimodal BERT_. Victor Milewski, Miryam de Lhoneux and Marie-Francine Moens.
- _Putting Words in BERT's Mouth: Navigating Contextualized Vector Spaces with Pseudowords_. Taelin Karidi, Yichu Zhou, Nathan Schneider, Omri Abend and Vivek Srikumar.
- _Explaining Classes through Word Attributions_. Samuel Rönnqvist, Amanda Myntti, Aki-Juhani Kyröläinen, Sampo Pyysalo, Veronika Laippala and Filip Ginter.

**Findings papers**
- _Don't Discard All the Biased Instances: Investigating a Core Assumption in Dataset Bias Mitigation Techniques_.
- _Distilling Word Meaning in Context from Pre-trained Language Models_. Chuhan Wu, Fangzhao Wu, Yang Yu, Tao Qi, Yongfeng Huang and Qi Liu.
- _Influence Tuning: Demoting Spurious Correlations via Instance Attribution and Instance-Driven Updates_. Xiaochuang Han and Yulia Tsvetkov.
- _Probing Across Time: What Does RoBERTa Know and When?_ Leo Z. Liu, Yizhong Wang, Jungo Kasai, Hannaneh Hajishirzi and Noah A. Smith.
- _Generating Realistic Natural Language Counterfactuals_. Marcel Robeer.
- _Probing Pre-trained Language Models for Semantic Attributes and their Values_. Meriem Beloucif.

Poster session 2 (gather.town)
----------------
**Archival papers**
- _Do contextual language embeddings distinguish between intersective and strictly subsective adjectives?_ Michael Goodale and Salvador Mascarenhas.
- _Analyzing BERT's Knowledge of Hypernymy via Prompting_. Michael Hanna and David Mareček.
- _An in-depth look at Euclidean disk embeddings for structure preserving parsing_. Federico Fancellu, Lan Xiao, Allan Jepson and Afsaneh Fazly.
- _Training Dynamic based data filtering may not work for NLP datasets_. Arka Talukdar, Monika Dagar, Prachi Gupta and Varun Menon.
- _Multi-Layer Random Perturbation Training for improving Model Generalization Efficiently_. Lis Kanashiro Pereira, Yuki Taya and Ichiro Kobayashi.
- _Screening Gender Transfer in Neural Machine Translation_. Guillaume Wisniewski, Lichao Zhu, Nicolas Bailler and François Yvon.
- _What BERT Based Language Model Learns in Spoken Transcripts: An Empirical Study_. Ayush Kumar, Mukuntha Narayanan Sundararaman and Jithendra Vepa.
- _Assessing the Generalization Capacity of Pre-trained Language Models through Japanese Adversarial Natural Language Inference_. Hitomi Yanaka and Koji Mineshima.
- _Investigating Negation in Pre-trained Vision-and-language Models_. Radina Dobreva and Frank Keller.
- _Not all parameters are born equal: Attention is mostly what you need_. Nikolay Bogoychev.
- _Not All Models Localize Linguistic Knowledge in the Same Place: A Layer-wise Probing on BERToids’ Representations_. Mohsen Fayyaz, Ehsan Aghazadeh, Ali Modarressi, Hosein Mohebbi and Mohammad Taher Pilehvar.
- _Learning Mathematical Properties of Integers_. Maria Ryskina and Kevin Knight.
- _Explaining NLP Models via Minimal Contrastive Editing (MiCE)_. Alexis Ross, Ana Marasović and Matthew Peters.
- _Probing Language Models for Understanding of Temporal Expressions_. Shivin Thukral, Kunal Kukreja and Christian Kavouras.
- _How Familiar Does That Sound? Cross-Lingual Representational Similarity Analysis of Acoustic Word Embeddings_. Badr M. Abdullah, Iuliia Zaitova, Tania Avgustinova, Bernd Möbius and Dietrich Klakow.
- _Perturbing Inputs for Fragile Interpretations in Deep Natural Language Processing_. Sanchit Sinha, Hanjie Chen, Arshdeep Sekhon, Yangfeng Ji and Yanjun Qi. 
- _An Investigation of Language Model Interpretability via Sentence Editing_. Samuel Stevens and Yu Su.
- _Interacting Knowledge Sources, Inspection and Analysis: Case-studies on Biomedical text processing_. Parsa Bagherzadeh and Sabine Bergler.
- _Attacks against Ranking Algorithms with Text Embeddings: {A} Case Study on Recruitment Algorithms_. Anahita Samadi, debapriya banerjee and Shirin Nilizadeh.
- _Controlled tasks for model analysis: Retrieving discrete information from sequences_. Ionut-Teodor Sorodoc, Gemma Boleda and Marco Baroni.
- _The Acceptability Delta Criterion: Testing Knowledge of Language using the Gradience of Sentence Acceptability_. Héctor Vázquez Martínez.
- _How Does BERT Rerank Passages? An Attribution Analysis with Information Bottlenecks_. Zhiying Jiang, Raphael Tang, Ji Xin and Jimmy Lin.
- _Do Language Models Know the Way to Rome?_ Bastien Liétard, Mostafa Abdou and Anders Søgaard.
- _Testing the linguistics of transformer generalizations_. Saliha Muradoglu and Mans Hulden.
- _Exploratory Model Analysis Using Data-Driven Neuron Representations_. Daisuke Oba, Naoki Yoshinaga and Masashi Toyoda.
- _Fine-Tuned Transformers Show Clusters of Similar Representations Across Layers_. Jason Phang, Haokun Liu and Samuel R. Bowman.
- _BERT Has Uncommon Sense: Similarity Ranking for Word Sense BERTology_. Luke Gessler and Nathan Schneider.

**Extended abstracts**
- _Generalization in neural sequence models: a case study in symbolic mathematics_. Sean Welleck, Peter West, Jize Cao and Yejin Choi.
- _Human Evaluation Study for Explaining Knowledge Graph Completion_. Timo Sztyler and Carolin Lawrence. 
- _Transformers Scan both Left and Right -- When they Have a Cue_. Jan H. Athmer and Denis Paperno.
- _Probing structures in the visual region embeddings from multimodal BERT_. Victor Milewski, Miryam de Lhoneux and Marie-Francine Moens.
- _Putting Words in BERT's Mouth: Navigating Contextualized Vector Spaces with Pseudowords_. Taelin Karidi, Yichu Zhou, Nathan Schneider, Omri Abend and Vivek Srikumar.
- _On Neurons Invariant to Sentence Structural Changes in Neural Machine Translation_. Gal Patel, Leshem Choshen and Omri Abend.
- _Explaining Classes through Word Attributions_. Samuel Rönnqvist, Amanda Myntti, Aki-Juhani Kyröläinen, Sampo Pyysalo, Veronika Laippala and Filip Ginter.

**Findings papers**
- _Making Heads and Tails of Models with Marginal Calibration for Sparse Tagsets_. Michael Kranzlein, Nelson F. Liu and Nathan Schneider.
- _Distilling Word Meaning in Context from Pre-trained Language Models_. Chuhan Wu, Fangzhao Wu, Yang Yu, Tao Qi, Yongfeng Huang, Qi Liu.
- _Probing Across Time: What Does RoBERTa Know and When?_ Leo Z. Liu, Yizhong Wang, Jungo Kasai, Hannaneh Hajishirzi and Noah A. Smith.
- _Probing Pre-trained Language Models for Semantic Attributes and their Values_. Meriem Beloucif.
- _Generating Realistic Natural Language Counterfactuals_. Marcel Robeer.
- _Influence Tuning: Demoting Spurious Correlations via Instance Attribution and Instance-Driven Updates_. Xiaochuang Han and Yulia Tsvetkov.


Poster session 3 (On site)
----------------
**Archival papers**
- _Exploratory Model Analysis Using Data-Driven Neuron Representations_. Daisuke Oba, Naoki Yoshinaga and Masashi Toyoda.
- _Fine-Tuned Transformers Show Clusters of Similar Representations Across Layers_. Jason Phang, Haokun Liu and Samuel R. Bowman.
- _BERT Has Uncommon Sense: Similarity Ranking for Word Sense BERTology_. Luke Gessler and Nathan Schneider.

**Extended abstracts**

**Findings papers**
- _Making Heads and Tails of Models with Marginal Calibration for Sparse Tagsets_. Michael Kranzlein, Nelson F. Liu and Nathan Schneider.
- _Distilling Word Meaning in Context from Pre-trained Language Models_. Chuhan Wu, Fangzhao Wu, Yang Yu, Tao Qi, Yongfeng Huang, Qi Liu.
- _Probing Across Time: What Does RoBERTa Know and When?_ Leo Z. Liu, Yizhong Wang, Jungo Kasai, Hannaneh Hajishirzi and Noah A. Smith.
- _Probing Pre-trained Language Models for Semantic Attributes and their Values_. Meriem Beloucif.

Poster session 3 (gather.town)
----------------
**Archival papers**
- _An Investigation of Language Model Interpretability via Sentence Editing_. Samuel Stevens and Yu Su.
- _Interacting Knowledge Sources, Inspection and Analysis: Case-studies on Biomedical text processing_. Parsa Bagherzadeh and Sabine Bergler.
- _Attacks against Ranking Algorithms with Text Embeddings: {A} Case Study on Recruitment Algorithms_. Anahita Samadi, debapriya banerjee and Shirin Nilizadeh.
- _Controlled tasks for model analysis: Retrieving discrete information from sequences_. Ionut-Teodor Sorodoc, Gemma Boleda and Marco Baroni.
- _The Acceptability Delta Criterion: Testing Knowledge of Language using the Gradience of Sentence Acceptability_. Héctor Vázquez Martínez.
- _How Does BERT Rerank Passages? An Attribution Analysis with Information Bottlenecks_. Zhiying Jiang, Raphael Tang, Ji Xin and Jimmy Lin.
- _Do Language Models Know the Way to Rome?_ Bastien Liétard, Mostafa Abdou and Anders Søgaard.
- _Testing the linguistics of transformer generalizations_. Saliha Muradoglu and Mans Hulden.
- _Exploratory Model Analysis Using Data-Driven Neuron Representations_. Daisuke Oba, Naoki Yoshinaga and Masashi Toyoda.
- _Fine-Tuned Transformers Show Clusters of Similar Representations Across Layers_. Jason Phang, Haokun Liu and Samuel R. Bowman.
- _BERT Has Uncommon Sense: Similarity Ranking for Word Sense BERTology_. Luke Gessler and Nathan Schneider.

**Extended abstracts**
- _Probing structures in the visual region embeddings from multimodal BERT_. Victor Milewski, Miryam de Lhoneux and Marie-Francine Moens.
- _Putting Words in BERT's Mouth: Navigating Contextualized Vector Spaces with Pseudowords_. Taelin Karidi, Yichu Zhou, Nathan Schneider, Omri Abend and Vivek Srikumar.
- _On Neurons Invariant to Sentence Structural Changes in Neural Machine Translation_. Gal Patel, Leshem Choshen and Omri Abend.
- _Explaining Classes through Word Attributions_. Samuel Rönnqvist, Amanda Myntti, Aki-Juhani Kyröläinen, Sampo Pyysalo, Veronika Laippala and Filip Ginter.

**Findings papers**
- _Making Heads and Tails of Models with Marginal Calibration for Sparse Tagsets_. Michael Kranzlein, Nelson F. Liu and Nathan Schneider.
- _Distilling Word Meaning in Context from Pre-trained Language Models_. Chuhan Wu, Fangzhao Wu, Yang Yu, Tao Qi, Yongfeng Huang, Qi Liu.
- _Probing Across Time: What Does RoBERTa Know and When?_ Leo Z. Liu, Yizhong Wang, Jungo Kasai, Hannaneh Hajishirzi and Noah A. Smith.
- _Probing Pre-trained Language Models for Semantic Attributes and their Values_. Meriem Beloucif.
- _Generating Realistic Natural Language Counterfactuals_. Marcel Robeer.
- _Influence Tuning: Demoting Spurious Correlations via Instance Attribution and Instance-Driven Updates_. Xiaochuang Han and Yulia Tsvetkov.
